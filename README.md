# Neulix DataHub ğŸ•¸ï¸

**Neulix DataHub** is a modular data collection and visualization platform built to run on a Raspberry Pi.  
It orchestrates web scrapers (spiders) through Airflow, stores cleaned data in Postgres, and provides real-time dashboards using Streamlit â€” all within Docker.

---

### ğŸ“Œ Key Features

- Automated scraping pipelines (e.g., LinkedIn, Facebook)
- Modular ETL design (spiders, transformers, loaders)
- Real-time KPI dashboards (Streamlit)
- Accessible via public web interface (Nginx reverse proxy)
- Lightweight enough to run on Raspberry Pi 4
- Exposable with HTTPS using DDNS and Letâ€™s Encrypt

---

### ğŸ§± Tech Stack

| Layer         | Tool                     |
|---------------|--------------------------|
| Orchestration | Apache Airflow           |
| Scraping      | BeautifulSoup + requests |
| ETL           | pandas, SQLAlchemy       |
| Storage       | PostgreSQL               |
| Visualization | Streamlit                |
| Proxy         | Nginx + Letâ€™s Encrypt    |
| Container     | Docker + docker-compose  |

---

### ğŸ—‚ Directory Overview

```bash
neulix_datahub/
â”œâ”€â”€ core/             # Airflow DAGs and helper scripts
â”œâ”€â”€ neulix_dataflow/  # Spiders, Transformers, Loaders
â”œâ”€â”€ neulix_interface/ # Streamlit dashboards
â”œâ”€â”€ nginx/            # Nginx reverse proxy config
â”œâ”€â”€ docker-compose.yml

ğŸš€ Getting Started
bash
Copiar
Editar
git clone https://github.com/seu-usuario/neulix_datahub.git
cd neulix_datahub
cp .env.example .env
docker-compose up --build -d

Then access:
http://localhost/airflow â€“ DAG management
http://localhost/dashboard â€“ Streamlit dashboards

ğŸ” Exposing to the Web
Use DuckDNS for free domain

Enable HTTPS with Letâ€™s Encrypt via Certbot

Configure Nginx for /airflow and /dashboard reverse proxy

ğŸ‘¨â€ğŸ’» Dev Notes
All spiders are in neulix_dataflow/spiders/, each one can be triggered by a DAG.
Dashboards are built on demand from the Postgres DB.
